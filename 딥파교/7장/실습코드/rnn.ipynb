{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbef0d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "211c59b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6289ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb8894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = load_dataset(\"imdb\")\n",
    "train_texts = raw[\"train\"][\"text\"]\n",
    "train_labels = raw[\"train\"][\"label\"]\n",
    "test_texts = raw[\"test\"][\"text\"]\n",
    "test_labels = raw[\"test\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfc7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4244c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, valid_texts, train_labels, valid_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=SEED, stratify=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5be252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have always been a huge James Bond fanatic! I have seen almost all of the films except for Die Another Day, and The World Is Not Enough. The graphic\\'s for Everything Or Nothing are breathtaking! The voice talents......... WOW! I LOVE PIERCE BROSNAN! He is finally Bond in a video game! HE IS BOND! I enjoyed the past Bond games: Goldeneye, The World Is Not Enough, Agent Under Fire, and Nightfire. This one is definitely the best! Finally, Mr. Brosnan, (may I call him Mr. Brosnan as a sign of respect? Yes I can!) He was phenomenally exciting to hear in a video game....... AT LONG LAST! DUH! I\\'ve seen him perform with Robin Williams, and let me tell you, they make a great team. Pierce Brosnan is funny, wickedly handsome ( I mean to say wickedly in a good way,) and just one of those actor\\'s who you would want to walk up to and wrap your arms around and hug, saying: \"Pierce Brosnan, thank you for being James Bond,\" \"If it wasn\\'t for you, I wouldn\\'t know who James Bond is.\" He\\'s a great actor! I am a huge fan of Willem Dafoe even though I\\'ve seen him in a couple of movies. His role as Nikolai Diavalo was brilliant. (Did I spell the character\\'s name right?) LOL!!!! He does a great job with an accent. Sometimes I can\\'t even hear an accent. I have seen Willem, I mean Mr. Dafoe, perform in two movies: Finding Nemo, and Spider-Man with my favorite actress: KIRSTEN DUNST! SHE ROCKS! Anyway, He never ceases to amaze. And Richard Kiel, wow, he\\'s definitely got the part of Jaw\\'s nailed. I\\'ve seen him in the movie\\'s and he\\'s awesome! As a matter of fact, my Grandparent\\'s have met Mr. Kiel, and I was jealous when they told me. But, Kirsten Dunst is at the top of my list of Celebritie\\'s that I want to meet. John Cleese was breathtaking. I have never seen a better person play as the wisecracking, and gadget creating Q! Mr. Cleese was hilarious! I\\'ve seen him work with Pierce Brosnan in Goldeneye and Tommorow Never Dies. He\\'s awesome! John Cleese\\'s most recent project is Shrek 2 starring Mike Myer\\'s, Cameron Diaz, Julie Andrew\\'s and Eddie Murphy. ( Shrek 2 is now in theatre\\'s!) GOOD LUCK 007! Oh, yeah, and as Q alway\\'s says: \"Grow up 007!\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d4e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tokenize(s: str):\n",
    "    # 소문자 + 간단한 정규화(알파벳/숫자/공백만 유지), 공백 기준 분리\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s.split() if s else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d8f7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "PAD, UNK = \"<pad>\", \"<unk>\"\n",
    "def build_vocab(texts, min_freq=MIN_FREQ):\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        counter.update(basic_tokenize(t))\n",
    "    # 자주 등장하는 토큰만 포함\n",
    "    itos = [PAD, UNK]\n",
    "    for token, freq in counter.most_common():\n",
    "        if freq >= min_freq:\n",
    "            itos.append(token)\n",
    "    stoi = {tok: idx for idx, tok in enumerate(itos)}\n",
    "    return stoi, itos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d988749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 42,871\n"
     ]
    }
   ],
   "source": [
    "stoi, itos = build_vocab(train_texts, MIN_FREQ)\n",
    "VOCAB_SIZE = len(itos)\n",
    "PAD_IDX = stoi[PAD]\n",
    "UNK_IDX = stoi[UNK]\n",
    "print(f\"Vocab size: {VOCAB_SIZE:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f698c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200 \n",
    "\n",
    "def encode(text, stoi_map=stoi, max_len=MAX_LEN):\n",
    "    toks = basic_tokenize(text)\n",
    "    ids = [stoi_map.get(tok, UNK_IDX) for tok in toks]\n",
    "    ids = ids[-max_len:]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49bc91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], int(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f375d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # batch: [(text_str, label_int), ...]\n",
    "    # 1) 인코딩\n",
    "    seqs = [encode(txt) for txt, _ in batch]\n",
    "    labels = torch.tensor([lab for _, lab in batch], dtype=torch.float32)\n",
    "\n",
    "    # 2) 패딩\n",
    "    lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    maxlen = max(lengths).item() if lengths.numel() > 0 else 0\n",
    "    padded = torch.full((len(seqs), maxlen), PAD_IDX, dtype=torch.long)\n",
    "    for i, s in enumerate(seqs):\n",
    "        if len(s) > 0:\n",
    "            padded[i, :len(s)] = torch.tensor(s, dtype=torch.long)\n",
    "    return padded, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "064c6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_ds = IMDBDataset(train_texts, train_labels)\n",
    "valid_ds = IMDBDataset(valid_texts, valid_labels)\n",
    "test_ds  = IMDBDataset(test_texts,  test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a13496a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1, dropout = 0.2, n_classes = 1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim \n",
    "        self.n_layers  = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size = embed_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: (B, T), lengths: (B,)\n",
    "        emb = self.embedding(x)  # (B, T, E)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_dim, device=x.device)\n",
    "        _, h_n = self.rnn(packed, h0)                    # h_n: (L, B, H)\n",
    "        h_last = h_n[-1]                                 # (B, H) 마지막 층\n",
    "        h_last = self.dropout(h_last)\n",
    "        logits = self.fc(h_last).squeeze(-1)            # (B,)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fa66de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(itos)\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb0e868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicRNN(num_layers = 1, hidden_dim = 256, vocab_size = vocab_size, embed_dim = 128, n_classes = n_classes, dropout = 0.5)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d59e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader):\n",
    "    model.train()\n",
    "    total_loss, total_acc, total_n = 0.0, 0.0, 0\n",
    "    for x, lengths, y in loader:       # <-- tuple 언패킹\n",
    "        x, lengths, y = x.to(DEVICE), lengths.to(DEVICE), y.float().to(DEVICE)\n",
    "\n",
    "        logits = model(x, lengths)      # (B,)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            bs = y.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            total_acc  += (preds == y).float().sum().item()\n",
    "            total_n    += bs\n",
    "    return total_loss / total_n, total_acc / total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d3f5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_n = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, lengths, y in loader:   # <-- tuple 언패킹\n",
    "            x, lengths, y = x.to(DEVICE), lengths.to(DEVICE), y.float().to(DEVICE)\n",
    "            logits = model(x, lengths)\n",
    "            loss = criterion(logits, y)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            bs = y.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            total_acc  += (preds == y).float().sum().item()\n",
    "            total_n    += bs\n",
    "    return total_loss / total_n, total_acc / total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac5c4db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH: 1], Validation Loss: 132.24 | Validation Accuracy:  0.57\n",
      "[EPOCH: 2], Validation Loss: 130.49 | Validation Accuracy:  0.62\n",
      "[EPOCH: 3], Validation Loss: 129.94 | Validation Accuracy:  0.68\n",
      "[EPOCH: 4], Validation Loss: 129.31 | Validation Accuracy:  0.70\n",
      "[EPOCH: 5], Validation Loss: 130.03 | Validation Accuracy:  0.57\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "LR = 0.001\n",
    "EPOCHS = 5\n",
    "for e in range(1, EPOCHS + 1):\n",
    "    train(model, optimizer, train_loader)\n",
    "    val_loss, val_accuracy = evaluate(model, valid_loader)\n",
    "    print(\"[EPOCH: %d], Validation Loss: %5.2f | Validation Accuracy: %5.2f\" % (e, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "898c1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 134.16 | Test Accuracy:  0.58\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % ( test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02930c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
