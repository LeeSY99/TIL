**LeNet-5** - 합성곱 신경망과 풀링을 반복적으로 거치고 fc층에서 분류를 수행하는 신경망

CNN을 최초로 도입

**AlexNet** - 기존보다 더 깊은 층 8층 (cnn 5층 fc 3층), gpu 2개를 기반으로한 병렬구조인 특징

ReLU사용, 드롭아웃, maxpooling(overlap풀링 - 겹치게 풀링), 데이터 증강(무작위 영역 크롭, 수평반전, 조명 변화[PCA])

**VGGNet** - 깊은 신경망이 높은 성능에 영향을 끼친다는 것을 증명

필터크기를 3*3고정, 최대풀링 필터 2*2고정

3*3으로 하는이유 - 필터크기가 크면 이미지가 빨리 축소되기 때문에 깊게 만들지 못함

3*3 필터 2번 = 5*5 필터 1번 → 특성맵 크기 같음

3*3 필터 3번 = 7*7 필터 1번 → 특성맵 크기 같음

→ 3*3 3번 컨볼루션 연산을 하는게 나은 이유 - 파라미터 개수가 적음(3*3 3개 → 27개, 7*7 1개 → 49개 가중치)

보통 성능을 높이려면 층을 깊게 쌓거나 노드를 늘리는 방법이 일반적

파라미터가 많아지면 성능이 올라가나? - 오히려 학습데이터에만 조점을 맞춰진 과대적합

연산량이 증가하고 컴퓨팅자원을 많이 사용. 기울기 소실 문제

**GoogLeNet**

가장 큰 특징 : **인셉션(Inception)**

효율적으로 특징을 추출하기위해 1*1, 3*3, 5*5의 합성곱 연산 수행 (3,5는 1*1로 차원 축소)

**보틀넥(bottleneck)** - 킨 필터를 거치기 전에 1*1필터로 채널 수(차원)을 줄여서 연산량을 줄이는 방식

**결론 : 여러 크기의 필터를 동시에 사용(Inception)하면서 1*1 필터로 보틀넥을 이용해 연산량을 줄이면서 성능은 향상**

**ResNet**

전체를 학습하지 않고 수정할 부분만 학습하는 원리

**H(x) - 원래 학습하고 싶은 목표 (필터 블록이 이상적으로 내야할 출력)**

**F(x) - 잔차(residual)**

**그래서 H(x)를 학습하지 않고 F(x)를 학습 → F(x) = H(x) - x 해서 gradient vanishing 문제를 보완**

bottleneck - 중간에 차원 맞추는 용

숏컷 (shortcut) - 필터를 통과하지 않고 입력을 보내주는 경로(?)

residual block - 차원별로 묶은 필터들의 집합

**객체 인식 - 이미지에서 여러 객체에 대해 각 객체 분류 + 위치 파악**

**1단계 객체 인식 - 분류 + 위치 동시**

**2단계 - 순차적**

**R-CNN** - 이미지 분류(CNN)과 객체가 있을만한 위치 후보 영역 제안

선택적탐색을 적용한 후보 영역을 많이 사용

**선택적 탐색** 

초기 영역 생성 - 이미지를 영역 다수개로 분할

작은 영역 통합 - 나눈 영역을 비슷한 것끼리 통합(그리디)

후보 영역 생성 - 통합된 이미지를 바탕으로 후보영역 추출

단점:

선택적탐색 ← 복잡

속도 문제

공간 파리미드 풀링

기존 cnn은 입력 크기를 고정시켜야 하는데 이때 이미지가 잘리거나 원래 생김새와 달라지는 문제점

입력 이미지의 크기와 상관없이 합성곱층을 통과시키고 fc층 전에 특성맵들을 동일한 크기로 조절하는 풀링층 → 이미지 훼손 x

**기존 cnn에서 fc층 때문에 이미지 크기를 고정시켜서 입력에 넣었는데 잘리거나 원래 모양과 달라지는 현상이 발생함.  그래서 이미지 그대로 입력에 넣고 특성 맵을 fc층에 넣기전에 고정 길이로 변환**

다양한 크기의 풀링을 해 concat하는 방식

**Fast R-CNN**

박스마다 cnn을 돌리는 R-CNN의 단점을 RoI풀링을 도입으로 개선

**RoI 풀링**

특성 맵에서 후보 영역(roi)을 정해진 크기에 맞추기 위해 영역을 적절히 나눠 maxpooling 계산

Faster R-CNN 

선택적 탐색(selective search)가 느린데 후보 선택 작업을 RPN에서 수행

**fast R-CNN + RPN(Region Proposal Network)**

**RPN** - 후보  영역 추출을 하는 네트워크

특성 맵 크기의 작은 윈도우 영역을 입력으로 받아 객채 존재 유뮤 판단

객체들의 크기와 비율이 다양해서 다양한 크기의 앵커박스를 활용해 객체 포착

이후 RoI풀링

**한줄정리: RPN 도입으로 후보 영역을 빠르게 산출 + 다양한 크기의 객체를 수용하기 위해 앵커박스 활용**

**이미지 분할(segmentation)**

1. **완전 합성곱**
    
    고정된 크기의 입력만 받아야하는 한계점 → fc층을 1*1 합성곱을 대체
    
    1*1 합성곱을 통과하면 히트맵이 남아 위치 파악
    
2. **합성곱 / 역합성곱 네트워크**
    
    완전 합성곱에서 위치 정보는 남지만 해상도가 낮아짐, 업샘플링을 하면서 일부 정보 잃어버림
    
    → 합성곱/역합성곱 네트워크 등장
    
    최종 출력 결과를 원래 입력 이미지와 같게 만들 수 있음
    
3. **U-Net**
    
    **수축 경로에는 특성을 포착/ 확장 경로는 포착한 특성을 가지고 지역화 수행**
    
    **지역화?** - 이미지 안에서 무엇이 있는지 어디에 있는지 예측하는 것
    
    FCN의 Skip Architecture와 Up-sampling을 활용해, 입력 이미지의 전체적인 의미와 지역화된 의미를 동시에 고려하는 모델을 만들어, segmetation에서 IOU의 향상을 가져옴
    
4. **PSPNet**
    
    **피라미드 풀링 모듈을 도입해 주변환경 정보를 활용해 세그멘테이션의 성능을 높임**
    
    피**라미드 풀링 모듈**
    
    여러 크기로 풀링하고 업샘플을 해 원래 크기로 되돌린 다음 합치는 모듈
    
5. **DeepLabv3(+)**
    
    **Atrous 합성곱 -** 커널 사이에 빈 공간을 둬 해상도는 유지하면서 수용영역을 키우는 합성곱
    
    **수용 영역** - 출력의 한 점이 원본 이미지의 얼마나 넓은 부분을 보고 결정되는지
    

**FCN(fully convolutional network)** - FC층을 없애고 끝까지 합성곱으로만 구성된 네트워크

업샘플 - 특징맵/이미지의 공간 해상도를 키우는 연산