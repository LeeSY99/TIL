{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40f39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcabf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train' : transforms.Compose([\n",
    "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean,std)\n",
    "            ]),\n",
    "            'val' : transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean,std)\n",
    "            ])\n",
    "        }\n",
    "    def __call__(self, img, phase):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2674f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "mean = (0.485,0.456,0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d69de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_directory = r'./chap06/data/dogs-vs-cats/Cat/'\n",
    "dog_directory = r'./chap06/data/dogs-vs-cats/Dog/'\n",
    "\n",
    "cat_image_filepaths = sorted([os.path.join(cat_directory, f) for f in os.listdir(cat_directory)])\n",
    "dog_image_filepaths = sorted([os.path.join(dog_directory, f) for f in os.listdir(dog_directory)])\n",
    "\n",
    "image_filepaths = [*cat_image_filepaths, *dog_image_filepaths]\n",
    "correct_image_filepaths = [i for i in image_filepaths if cv2.imread(i) is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b422f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(correct_image_filepaths)\n",
    "train_images_filepaths = correct_image_filepaths[:400]    \n",
    "val_images_filepaths = correct_image_filepaths[400:-10]  \n",
    "test_images_filepaths = correct_image_filepaths[-10:]    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14190f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "92\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images_filepaths))\n",
    "print(len(val_images_filepaths))\n",
    "print(len(test_images_filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef1bcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogvsCatDataset(Dataset):    \n",
    "    def __init__(self, file_list, transform=None, phase='train'):    \n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):       \n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)        \n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "        \n",
    "        label = img_path.split('/')[-1].split('.')[0]\n",
    "        if label == 'dog':\n",
    "            label = 1\n",
    "        elif label == 'cat':\n",
    "            label = 0\n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4683b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogvsCatDataset(train_images_filepaths, transform=ImageTransform(size, mean,std), phase = 'train')\n",
    "val_dataset = DogvsCatDataset(val_images_filepaths, transform=ImageTransform(size, mean, std), phase='val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7216bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_iterator = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader_dict = {'train': train_iterator, 'val': valid_iterator}\n",
    "\n",
    "batch_iterator = iter(train_iterator)\n",
    "inputs, label = next(batch_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da35c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac9818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.batchnorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.reul = nn.ReLU(inplace=True)\n",
    "\n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample == nn.Sequential(conv,bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        i = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28979824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample = False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion*out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            bn = nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        i = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc41ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim, zero_init_residual=False):\n",
    "        super().__init__()\n",
    "\n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "\n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride=1):\n",
    "        layers = []\n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion*channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef9329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetConfig = namedtuple('ResNetConfig' , ['block','n_blocks','channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "627da5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_config = ResNetConfig(block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512])\n",
    "resnet34_config = ResNetConfig(block = BasicBlock, n_blocks = [3,4,6,3], channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9332bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_config = ResNetConfig(block = Bottleneck, n_blocks = [3, 4, 6, 3], channels = [64, 128, 256, 512])\n",
    "resnet101_config = ResNetConfig(block = Bottleneck,  n_blocks = [3, 4, 23, 3], channels = [64, 128, 256, 512])\n",
    "resnet152_config = ResNetConfig(block = Bottleneck, n_blocks = [3, 8, 36, 3], channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "165efc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model = ResNet(resnet50_config, OUTPUT_DIM)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "207ca991",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f399a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topk_accuracy(y_pred, y, k = 2):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    return acc_1, acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed8f5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.train()    \n",
    "    for (x, y) in iterator:        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "            \n",
    "        optimizer.zero_grad()                \n",
    "        y_pred = model(x)  \n",
    "        \n",
    "        loss = criterion(y_pred[0], y) \n",
    "        \n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)        \n",
    "        loss.backward()        \n",
    "        optimizer.step()        \n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd93a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.eval()    \n",
    "    with torch.no_grad():        \n",
    "        for (x, y) in iterator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)            \n",
    "            loss = criterion(y_pred[0], y)\n",
    "            acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "767e01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "969c902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.756 | Train Acc @1:  50.48% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.720 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.745 | Train Acc @1:  50.24% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.727 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.747 | Train Acc @1:  50.00% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.739 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.746 | Train Acc @1:  50.24% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.751 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.747 | Train Acc @1:  50.24% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.755 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.731 | Train Acc @1:  51.20% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.751 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.735 | Train Acc @1:  49.76% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.747 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.740 | Train Acc @1:  50.24% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.752 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.742 | Train Acc @1:  49.04% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.751 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.729 | Train Acc @1:  50.24% | Train Acc @5: 100.00%\n",
      "\tValid Loss: 0.748 | Valid Acc @1:  48.81% | Valid Acc @5: 100.00%\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion, device)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './chap06/ResNet-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | ' \\\n",
    "          f'Train Acc @5: {train_acc_5*100:6.2f}%')\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc @1: {valid_acc_1*100:6.2f}% | ' \\\n",
    "          f'Valid Acc @5: {valid_acc_5*100:6.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157dc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
