{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcd65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "matplotlib.style.use('ggplot')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c75c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f57199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(r'..\\chap08\\data\\archive\\train', transform=train_transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(r'..\\chap08\\data\\archive\\test', transform=val_transform)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7d50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(pretrained=True, requires_grad=False):\n",
    "    model = models.resnet50(progress=True, pretrained=pretrained)\n",
    "    if requires_grad == False:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif requires_grad == True:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    model.fc = nn.Linear(2048,2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a46c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRScheduler():\n",
    "    def __init__(self, optimizer, patience=5, min_lr=1e-6, factor=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "        ##성능개선이 없을때 학습률을 factor배로 줄임\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            patience=self.patience, #학습률을 조절하기 전에 몇번 기다려야 하는지\n",
    "            factor=self.factor, #학습률을 얼마나 감소시킬지\n",
    "            min_lr=self.min_lr, #학습률 하한선\n",
    "            verbose=True\n",
    "        )\n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='./early_stop_ckpt.pt'):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = nn.inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'Early Stopping counter : {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73cccf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr-scheduler', dest='lr_scheduler', action='store_true')\n",
    "parser.add_argument('--early-stopping', dest='early_stopping', action='store_true')\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\") \n",
    "args = vars(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e47b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation device: cuda\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25,557,032 total parameters.\n",
      "25,557,032 training parameters.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Computation device: {device}\\n\")\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "937b800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27861157",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot_name = 'loss'\n",
    "acc_plot_name = 'accuracy'\n",
    "model_name = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9026f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['lr_scheduler']:\n",
    "    print('INFO: Initializing learningrate scheduler')\n",
    "    lr_scheduler = LRScheduler(optimizer)\n",
    "    loss_plot_name = 'lrs_loss'\n",
    "    acc_plot_name = 'lrs_accuracy'\n",
    "    model_name = 'lrs_model'\n",
    "\n",
    "if args['early_stopping']:\n",
    "    print('INFO: Initializing early stopping')\n",
    "    early_stopping = EarlyStopping()\n",
    "    loss_plot_name = 'es_loss'\n",
    "    acc_plot_name = 'es_accuracy'\n",
    "    model_name = 'es_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41f651a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dataloader, train_dataset, optimizer, criterion):\n",
    "    print('Training')\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    prog_bar = tqdm(enumerate(train_dataloader), total=int(len(train_dataset)/train_dataloader.batch_size))\n",
    "    for i, data in prog_bar:\n",
    "        counter += 1\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        total += target.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        train_running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == target).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_running_loss / counter\n",
    "    train_accuracy = 100. * train_running_correct / total\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccd8b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, test_dataloader, val_dataset, criterion):\n",
    "    print('Validating')\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    prog_bar = tqdm(enumerate(test_dataloader), total=int(len(val_dataset)/test_dataloader.batch_size))\n",
    "    with torch.no_grad():\n",
    "        for i, data in prog_bar:\n",
    "            counter += 1\n",
    "            data, target = data[0].to(device), data[1].to(device)\n",
    "            total += target.size(0)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            \n",
    "            val_running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_running_correct += (preds == target).sum().item()\n",
    "        \n",
    "        val_loss = val_running_loss / counter\n",
    "        val_accuracy = 100. * val_running_correct / total\n",
    "        return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69884de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:03,  4.13it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:02,  5.62it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1754, Train Acc: 58.63\n",
      "Val Loss: 22.4733, Val Acc: 49.80\n",
      "Epoch 2 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:03,  4.84it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:02,  5.52it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5662, Train Acc: 69.88\n",
      "Val Loss: 1.1955, Val Acc: 62.60\n",
      "Epoch 3 of 100\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:03,  4.85it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:01<00:00,  5.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m train_epoch_loss, train_epoch_accuracy = training(\n\u001b[32m      7\u001b[39m     model, train_dataloader, train_dataset, optimizer, criterion\n\u001b[32m      8\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m val_epoch_loss, val_epoch_accuracy = \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m train_loss.append(train_epoch_loss)\n\u001b[32m     13\u001b[39m train_accuracy.append(train_epoch_accuracy)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m(model, test_dataloader, val_dataset, criterion)\u001b[39m\n\u001b[32m      8\u001b[39m prog_bar = tqdm(\u001b[38;5;28menumerate\u001b[39m(test_dataloader), total=\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_dataset)/test_dataloader.batch_size))\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[39m, in \u001b[36mDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    index (int): Index\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m \u001b[33;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m path, target = \u001b[38;5;28mself\u001b[39m.samples[index]\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m     sample = \u001b[38;5;28mself\u001b[39m.transform(sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[39m, in \u001b[36mdefault_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\torchvision\\datasets\\folder.py:264\u001b[39m, in \u001b[36mpil_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    263\u001b[39m     img = Image.open(f)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\PIL\\Image.py:984\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBGR;15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;24\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    982\u001b[39m     deprecate(mode, \u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sd39a\\anaconda3\\envs\\study\\Lib\\site-packages\\PIL\\ImageFile.py:300\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    299\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m n, err_code = \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = [], []\n",
    "val_loss, val_accuracy = [], []\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_accuracy = training(\n",
    "        model, train_dataloader, train_dataset, optimizer, criterion\n",
    "    )\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(\n",
    "        model, val_dataloader, val_dataset, criterion\n",
    "    )\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "    if args['lr_scheduler']:\n",
    "        lr_scheduler(val_epoch_loss)\n",
    "    if args['early_stopping']:\n",
    "        early_stopping(val_epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_accuracy:.2f}\")\n",
    "    print(f'Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f}')\n",
    "end = time.time()\n",
    "print(f\"Training time: {(end-start)/60:.3f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
    "plt.plot(val_accuracy, color='blue', label='validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(f\"./img/{acc_plot_name}.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(val_loss, color='red', label='validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(f\"./img/{loss_plot_name}.png\")\n",
    "plt.show()\n",
    "    \n",
    "print('Saving model...')\n",
    "torch.save(model.state_dict(), f\"./img/{model_name}.pth\")\n",
    "print('TRAINING COMPLETE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
