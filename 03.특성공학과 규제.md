
k-최근접 이웃 회귀 : k최근접 이웃 분류처럼 예측 샘플에 가장 가까운 샘플 k개를 골라 평균을 내 예측

결정계수 (R^2): 회귀문제 성능측정 도구 중 하나 1에 가까울수록 성능 좋음

과대적합: 훈련세트에 지나치게 학습해, 새로운 데이터에는 일반화 성능이 떨어지는 현상

---

knn-회귀가 문제인 경우 

가까운 샘플의 평균을 내다보니 범위 밖의 데이터 예측이 불가능함(범위 밖 데이터가 들어오면 항상 같은 값을 예측하게 됨 - 가장 가까운 k개가 항상 같다보니)

이상치가 평균값을 크게 바꿈

근처 데이터가 적을 때 몇 개 값이 크게 왜곡

knn-분류가 문제인 경우

차원이 커질수록 모든 점들이 비슷하게 멀어짐 → 정확도 하락

데이터가 불균형할때 소수 클래스는 무시되기 쉬움

결정경계가 불안정 - 서로다른 클래스가 섞인 경계부근에서 작은 변화에 민감

선형회귀: 한 직선을 학습

→ 무슨 선일까? 특성을 잘 나타낼 수 있는 직선

직선 선형회귀의 한계 : 

현실 데이터는 비선형인 경우가 많은데 단순 직선하나로 표현하기엔 부족

다항회귀: 다항식을 사용한 선형회귀 → 좀 더 항을 추가해 특성에 좀 더 맞게 학습가능

비선형으로 보일 수 있지만 선형회귀로 표현 가능

---

다중회귀 : 여러개의 특성을 사용한 선형회귀

다항회귀와의 차이? 

다항회귀: 독립변수 1개로 거듭제곱 항을 추가해서 곡선 관계 모델링

다중회귀: 서로 다른 독립변수(특성)을 사용해 하나의 종속변수를 예측하는 회귀

독립함수(입력, 특징): 원인, 조건으로 삼음, 종속변수에 영향을 줌

종속변수(출력, 라벨): 예측하고자하는 목표값

특성공학: 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업.

기존 특성을 활용해 새 특성을 만들거나, 스케일 조정하거나, 중요한 특성만 선택할 수 있음

규제: 과대적합을 줄이는 방법 중 하나

릿지: 계수를 줄임 (0에 가깝게)

라쏘: 일부 계수를 0으로 (변수 선택 자동)
