**누락된 값 처리** - 버리거나 평균/중앙값으로 대체 (뭐가 최선인지는 실험해봐야 함)

**중요!** : 테스트셋에는 항상 **훈련세트의 통계값으로 적용**해야함!!

**절편** : 데이터 전체의 평균을 맞추는 기준

기존 머신러닝 모델에서는 어떻게 계수와 절편이 저런 값으로 학습했는지, 어떤 기준으로 예측됐는지 알 수 없음 → 학습의 결과를 설명하기 어렵다

 **결정트리** - 조건을 설정해 분류를 함 (조건문과 유사)

리프노드에서 가장 많은 클래스가 예측 클래스가 됨

장점: 분류 기준을 사람이 직관적으로 이해하기 쉬움, 스케일링 필요없음

단점: 트리가 너무 깊고, 노드가 많으면 오히려 이해하거나 읽기 어려움

**지니 불순도**

$$
1-(음성 클래스 비율^2 + 양성 클래스 비율^2)
$$

      최악이라면 반반씩 섞여있음 → 0.5

최고라면 한쪽 클래스 비율은 1, 나머지 클래스 비율 0 → 1

**정보이득 -** 부모노드와 자식노드 사이의 불순도 차이

**가지치기** - 트리의 깊이를 제한해 과적합을 막음

트리가 깊으면 훈련세트에 대해 세세하게 나누기 때문에 과적합 가능성

트리의 노드 분할은 지니 불순도가 최소화 되게끔 분할

---

**검증세트** - 모델이 잘 학습됐는지 검증하는 데이터셋

**검증셋을 만드는 이유** - 훈련과 테스트셋만 사용하면 결국은 테스트셋에 맞춰서 모델을 조정하게 됨. 테스트셋은 일반화 성능을 확인하는 용도(마지막에 1번만). 

**교차검증Cross Validation** - 훈련세트를 K개로 나누어 번갈아가면서 검증셋 나머지는 훈련셋으로 사용 

모든 데이터가 훈련에 참여할 수 있어서 성능 향상

### 하이퍼파리미터 튜닝

**하이퍼파라미터** - 사람이 지정해야 하는 파리미터

**그리드서치 (Grid Search)** : 사용자가 설정한 하이터파라미터 후보로 학습 + 교차검증 → 이후 최적의 하이퍼 파라미터 값 호출

장: 설정 범위 내에서 반드시 최적 해를 찾을 수 있다. 

결과 해석 유리

단: 계산 비용 큼, 중요하지 않은 구간도 연산함

**랜덤 서치 (Random Search)** : 사용자가 설정한 범위에서 무작위로 골라 학습 + 교차검증

확률은 균등분포

장: 효율적 탐색 - 무작위여서 좋은 성능을 낼 가능성

적은 시도로 최적의 해 찾기 가능

단: 최적해 보장 x

파라미터별 성능 변화 체크 힘듬

---

**정형 데이터** : 구조화 된 데이터 (csv, db 등)

**비정형 데이터** : 구조화 되지 않음(이미지, 음성, 텍스트 등)

**앙상블 학습** - 여러개의 개별 학습기를 결합해 하나의 강력한 모델을 만듬

- **랜덤 포레스트** - 결정 트리를 랜덤하게 만들어 각 트리의 예측으로 최종 예측
    - **부트스트랩 샘플** - 입력 데이터에서 무작위로 하나씩 입력 크기만큼 뽑음 [데이터가 100개면 100번]  (복원추출 느낌)
    - 특성을 전체 특성의 제곱근만큼 랜덤하게 선택 (특성이 9개면 3개 랜덤으로 골라 학습)
    
    → 일부 특성과 샘플만 사용해 훈련세트에 과적합 막아줌
    
    - OOB 샘플 - 부트스트랩에 포함되지 않은 샘플 → 이걸로 검증셋의 역할을 함
- **엑스트라 트리** - 부트스트랩 샘플 사용 안함, 노드 분할 랜덤
- **그래디언트 부스팅** - 얕은 트리를 여러개 사용해 손실이 가장 낮은곳으로 학습→ 과적합에 강하고 높은 일반화 성능
- 히스토그램기반 그래디언트 부스팅,  XGBoost, LightGBM
    - 각 특징 구간을 구간으로 나눔
    - 원래는 수많은 분할 후보를 모두 검사해야 했음
    - 그런데 히스토그램 기반은 보통 256개 구간으로 나눠서 그 구간을 분할 기준으로 함 → 속도 빠름, 메모리 절약
    - 결측치 같은 전용 구간도 있어 전처리 필요없음
